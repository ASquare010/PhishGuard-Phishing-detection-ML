{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "file_path = 'features_extracted_V2.csv'  # Replace with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separating out a sample for prediction\n",
    "predict_rows = df.sample(60, random_state=13)\n",
    "df = df.drop(predict_rows.index)\n",
    "\n",
    "# Separating features and label\n",
    "df_Y = df['label']\n",
    "df_X = df.drop('label', axis=1)\n",
    "\n",
    "# Preparing the training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_X)\n",
    "df_X_scaled = scaler.transform(df_X)\n",
    "joblib.dump(scaler, 'scaler_model.joblib')\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X_scaled, df_Y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Transform your predict_rows for prediction\n",
    "\n",
    "predict_features = predict_rows.drop('label', axis=1)\n",
    "predict_labels = predict_rows['label']\n",
    "\n",
    "# Scale the features of the 15 rows\n",
    "predict_features_scaled = scaler.transform(predict_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration 1 - Test Set Evaluation:\n",
      "Accuracy: 97.76384535005225\n",
      "Precision: 97.16070414537195\n",
      "F1 Score: 96.96797959761973\n",
      "Recall: 96.77601809954751\n",
      "ROC AUC: 97.55937133018476\n",
      "Confusion Matrix: [[2967   50]\n",
      " [  57 1711]]\n",
      "Combined Metric: 97.4622747477121\n",
      "-----------------------------------------\n",
      "\n",
      "Prediction on 15 Rows:\n",
      "Predicted Labels: [0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual Labels: [0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "-----------------------------------------\n",
      "\n",
      "Model Configuration 2 - Test Set Evaluation:\n",
      "Accuracy: 97.76384535005225\n",
      "Precision: 97.21432632177374\n",
      "F1 Score: 96.96626027785653\n",
      "Recall: 96.71945701357465\n",
      "ROC AUC: 97.54766354159011\n",
      "Confusion Matrix: [[2968   49]\n",
      " [  58 1710]]\n",
      "Combined Metric: 97.48908583591299\n",
      "-----------------------------------------\n",
      "\n",
      "Prediction on 15 Rows:\n",
      "Predicted Labels: [0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual Labels: [0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "-----------------------------------------\n",
      "\n",
      "Model Configuration 3 - Test Set Evaluation:\n",
      "Accuracy: 97.63845350052247\n",
      "Precision: 97.47561675272519\n",
      "F1 Score: 96.78154371973797\n",
      "Recall: 96.0972850678733\n",
      "ROC AUC: 97.31944134069835\n",
      "Confusion Matrix: [[2973   44]\n",
      " [  69 1699]]\n",
      "Combined Metric: 97.55703512662383\n",
      "-----------------------------------------\n",
      "\n",
      "Prediction on 15 Rows:\n",
      "Predicted Labels: [0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual Labels: [0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "-----------------------------------------\n",
      "\n",
      "Model Configuration 4 - Test Set Evaluation:\n",
      "Accuracy: 97.57575757575758\n",
      "Precision: 97.85631517960603\n",
      "F1 Score: 96.68002289639382\n",
      "Recall: 95.5316742081448\n",
      "ROC AUC: 97.15264519157655\n",
      "Confusion Matrix: [[2980   37]\n",
      " [  79 1689]]\n",
      "Combined Metric: 97.7160363776818\n",
      "-----------------------------------------\n",
      "\n",
      "Prediction on 15 Rows:\n",
      "Predicted Labels: [0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual Labels: [0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "-----------------------------------------\n",
      "\n",
      "The best model configuration is [('mlp', MLPClassifier(alpha=0.001, hidden_layer_sizes=(20,), learning_rate='adaptive',\n",
      "              max_iter=500)), ('knn', KNeighborsClassifier(leaf_size=15, n_neighbors=20, p=1, weights='distance')), ('svm', SVC(C=10))] with a combined metric of 97.72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_model.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "best_precision_accuracy = 0\n",
    "best_config = None\n",
    "best_model = None\n",
    "\n",
    "base_learners_set1 = [('rf', RandomForestClassifier(criterion='entropy', max_features='sqrt', min_samples_leaf=1, min_samples_split=3, n_estimators=100)), \n",
    "                      ('mlp', MLPClassifier(max_iter=500, activation='relu', alpha=0.001, hidden_layer_sizes=(20,), learning_rate='adaptive', solver='adam')),\n",
    "                      ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=15, n_neighbors=20, p=1, weights='distance'))]\n",
    "\n",
    "base_learners_set2 = [('rf', RandomForestClassifier(criterion='entropy', max_features='sqrt', min_samples_leaf=1, min_samples_split=3, n_estimators=100)), \n",
    "                      ('mlp', MLPClassifier(max_iter=500, activation='relu', alpha=0.001, hidden_layer_sizes=(20,), learning_rate='adaptive', solver='adam')), \n",
    "                      ('svm', SVC(C=10, kernel='rbf', tol=0.001))]\n",
    "\n",
    "base_learners_set3 = [('rf', RandomForestClassifier(criterion='entropy', max_features='sqrt', min_samples_leaf=1, min_samples_split=3, n_estimators=100)),\n",
    "                      ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=15, n_neighbors=20, p=1, weights='distance')), \n",
    "                      ('svm', SVC(C=10, kernel='rbf', tol=0.001))]\n",
    "\n",
    "base_learners_set4 = [('mlp', MLPClassifier(max_iter=500, activation='relu', alpha=0.001, hidden_layer_sizes=(20,), learning_rate='adaptive', solver='adam')),\n",
    "                      ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=15, n_neighbors=20, p=1, weights='distance')), \n",
    "                      ('svm', SVC(C=10, kernel='rbf', tol=0.001))]\n",
    "\n",
    "base_learners = [base_learners_set1, base_learners_set2, base_learners_set3, base_learners_set4]\n",
    "\n",
    "for idx, base_learner_group in enumerate(base_learners):\n",
    "    meta_learner = LogisticRegression()\n",
    "    clf = StackingClassifier(estimators=base_learner_group, final_estimator=meta_learner)\n",
    "\n",
    "    # Train the model on the full training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set and evaluate\n",
    "    test_predictions = clf.predict(X_test)\n",
    "    precision = precision_score(y_test, test_predictions) * 100\n",
    "    accuracy = accuracy_score(y_test, test_predictions) * 100\n",
    "    combined_metric = (precision + accuracy) / 2  # You can adjust the combination based on your preference\n",
    "\n",
    "    print(f'Model Configuration {idx + 1} - Test Set Evaluation:')\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('F1 Score:', f1_score(y_test, test_predictions) * 100)\n",
    "    print('Recall:', recall_score(y_test, test_predictions) * 100)\n",
    "    print('ROC AUC:', roc_auc_score(y_test, test_predictions) * 100)\n",
    "    print('Confusion Matrix:', confusion_matrix(y_test, test_predictions))\n",
    "    print('Combined Metric:', combined_metric)\n",
    "    print('-----------------------------------------\\n')\n",
    "\n",
    "    # Predict on the 15 rows and compare with actual labels\n",
    "    predict_predictions = clf.predict(predict_features_scaled)\n",
    "    print('Prediction on 15 Rows:')\n",
    "    print('Predicted Labels:', predict_predictions)\n",
    "    print('Actual Labels:', predict_labels.values)\n",
    "    print('-----------------------------------------\\n')\n",
    "\n",
    "    # Save the best configuration and model based on the combined metric\n",
    "    if combined_metric > best_precision_accuracy:\n",
    "        best_precision_accuracy = combined_metric\n",
    "        best_config = base_learner_group\n",
    "        best_model = clf\n",
    "\n",
    "# Now, best_config contains the base learners configuration, and best_model contains the best StackingClassifier.\n",
    "print(f'The best model configuration is {best_config} with a combined metric of {best_precision_accuracy:.2f}')\n",
    "\n",
    "# Save the best model to a file (you can choose the serialization method based on your preferences)\n",
    "\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
