{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "file_path = 'urldata.csv'  # Replace with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df = df.drop('Domain', axis=1)\n",
    "\n",
    "# Separating out a sample for prediction\n",
    "predict_rows = df.sample(15, random_state=42)\n",
    "df = df.drop(predict_rows.index)\n",
    "\n",
    "# Separating features and label\n",
    "df_Y = df['Label']\n",
    "df_X = df.drop('Label', axis=1)\n",
    "\n",
    "# Preparing the training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_X)\n",
    "df_X_scaled = scaler.transform(df_X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X_scaled, df_Y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Transform your predict_rows for prediction\n",
    "\n",
    "predict_features = predict_rows.drop('Label', axis=1)\n",
    "predict_labels = predict_rows['Label']\n",
    "\n",
    "# Scale the features of the 15 rows\n",
    "predict_features_scaled = scaler.transform(predict_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation:\n",
      "Accuracy: 91.20283510527413\n",
      "F1 Score: 90.48692515779982\n",
      "Recall: 83.729662077597\n",
      "Precision: 98.43060323688081\n",
      "ROC AUC: 91.19816437213183\n",
      "Confusion Matrix: [[2368   32]\n",
      " [ 390 2007]]\n",
      "-----------------------------------------\n",
      "\n",
      "Prediction on 15 Rows:\n",
      "Predicted Labels: [0 1 1 0 1 0 0 0 0 0 0 0 1 0 0]\n",
      "Actual Labels: [0 1 1 1 1 0 0 0 1 1 0 1 1 0 0]\n",
      "-----------------------------------------\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 91.20283510527413\n",
      "F1 Score: 90.48692515779982\n",
      "Recall: 83.729662077597\n",
      "Precision: 98.43060323688081\n",
      "ROC AUC: 91.19816437213183\n",
      "Confusion Matrix: [[2368   32]\n",
      " [ 390 2007]]\n",
      "-----------------------------------------\n",
      "\n",
      "Prediction on 15 Rows:\n",
      "Predicted Labels: [0 1 1 0 1 0 0 0 0 0 0 0 1 0 0]\n",
      "Actual Labels: [0 1 1 1 1 0 0 0 1 1 0 1 1 0 0]\n",
      "-----------------------------------------\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 91.20283510527413\n",
      "F1 Score: 90.48692515779982\n",
      "Recall: 83.729662077597\n",
      "Precision: 98.43060323688081\n",
      "ROC AUC: 91.19816437213183\n",
      "Confusion Matrix: [[2368   32]\n",
      " [ 390 2007]]\n",
      "-----------------------------------------\n",
      "\n",
      "Prediction on 15 Rows:\n",
      "Predicted Labels: [0 1 1 0 1 0 0 0 0 0 0 0 1 0 0]\n",
      "Actual Labels: [0 1 1 1 1 0 0 0 1 1 0 1 1 0 0]\n",
      "-----------------------------------------\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 90.93183239524703\n",
      "F1 Score: 90.20490880432335\n",
      "Recall: 83.56278681685441\n",
      "Precision: 97.99412915851272\n",
      "ROC AUC: 90.92722674176053\n",
      "Confusion Matrix: [[2359   41]\n",
      " [ 394 2003]]\n",
      "-----------------------------------------\n",
      "\n",
      "Prediction on 15 Rows:\n",
      "Predicted Labels: [0 1 1 0 1 0 0 0 0 0 0 0 1 0 0]\n",
      "Actual Labels: [0 1 1 1 1 0 0 0 1 1 0 1 1 0 0]\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "'''\n",
    "base_learners = [('rf', RandomForestClassifier(criterion='entropy', max_features='auto', min_samples_leaf=1, min_samples_split=3, n_estimators=100)), \n",
    "                ('mlp', MLPClassifier(max_iter=500, activation='relu', alpha=0.001, hidden_layer_sizes=(20,), learning_rate='adaptive', solver='adam')),\n",
    "                ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=15, n_neighbors=20, p=1, weights='distance')), \n",
    "                ('svm', SVC(C=10, kernel='rbf', tol=0.001))]\n",
    "'''\n",
    "\n",
    "base_learners_set1 = [('rf', RandomForestClassifier(criterion='entropy', max_features='sqrt', min_samples_leaf=1, min_samples_split=3, n_estimators=100)), \n",
    "                ('mlp', MLPClassifier(max_iter=500, activation='relu', alpha=0.001, hidden_layer_sizes=(20,), learning_rate='adaptive', solver='adam')),\n",
    "                ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=15, n_neighbors=20, p=1, weights='distance'))]\n",
    "\n",
    "base_learners_set2 = [('rf', RandomForestClassifier(criterion='entropy', max_features='sqrt', min_samples_leaf=1, min_samples_split=3, n_estimators=100)), \n",
    "                ('mlp', MLPClassifier(max_iter=500, activation='relu', alpha=0.001, hidden_layer_sizes=(20,), learning_rate='adaptive', solver='adam')), \n",
    "                ('svm', SVC(C=10, kernel='rbf', tol=0.001))]\n",
    "\n",
    "base_learners_set3 = [('rf', RandomForestClassifier(criterion='entropy', max_features='sqrt', min_samples_leaf=1, min_samples_split=3, n_estimators=100)),\n",
    "                ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=15, n_neighbors=20, p=1, weights='distance')), \n",
    "                ('svm', SVC(C=10, kernel='rbf', tol=0.001))]\n",
    "\n",
    "base_learners_set4 = [('mlp', MLPClassifier(max_iter=500, activation='relu', alpha=0.001, hidden_layer_sizes=(20,), learning_rate='adaptive', solver='adam')),\n",
    "                ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=15, n_neighbors=20, p=1, weights='distance')), \n",
    "                ('svm', SVC(C=10, kernel='rbf', tol=0.001))]\n",
    "\n",
    "\n",
    "base_learners = [base_learners_set1, base_learners_set2, base_learners_set3, base_learners_set4]\n",
    "\n",
    "for base_learner_group in base_learners:\n",
    "    meta_learner = LogisticRegression()\n",
    "    clf = StackingClassifier(estimators=base_learner_group, final_estimator=meta_learner)\n",
    "\n",
    "    # Train the model on the full training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set and evaluate\n",
    "    test_predictions = clf.predict(X_test)\n",
    "    print('Test Set Evaluation:')\n",
    "    print('Accuracy:', accuracy_score(y_test, test_predictions)*100)\n",
    "    print('F1 Score:', f1_score(y_test, test_predictions)*100)\n",
    "    print('Recall:', recall_score(y_test, test_predictions)*100)\n",
    "    print('Precision:', precision_score(y_test, test_predictions)*100)\n",
    "    print('ROC AUC:', roc_auc_score(y_test, test_predictions)*100)\n",
    "    print('Confusion Matrix:', confusion_matrix(y_test, test_predictions))\n",
    "    print('-----------------------------------------\\n')\n",
    "\n",
    "    # Predict on the 15 rows and compare with actual labels\n",
    "    predict_predictions = clf.predict(predict_features_scaled)\n",
    "    print('Prediction on 15 Rows:')\n",
    "    print('Predicted Labels:', predict_predictions)\n",
    "    print('Actual Labels:', predict_labels.values)\n",
    "    print('-----------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
